{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j6aeGKTIYYEu"
   },
   "source": [
    "# Baseline Model\n",
    "\n",
    "## Table of Contents\n",
    "1. [Model Choice](#model-choice)\n",
    "2. [Feature Selection](#feature-selection)\n",
    "3. [Implementation](#implementation)\n",
    "4. [Evaluation](#evaluation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ngt2AC0rYYE4"
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras import metrics\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.utils\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ovSfYAPLe3F-"
   },
   "source": [
    "## Model Choice\n",
    "For this binary image classification task (distinguishing between **HP (benign polyp)** and **SSA (malignant adenoma)** classes), we considered and experimented with a custom Convolutional Neural Network (CNN) --> a basic CNN architecture with three convolutional blocks followed by dense layers.\n",
    "\n",
    "* to establish a baseline performance.\n",
    "* full control over architecture and training.\n",
    "* Lightweight and suitable for quick iteration and debugging.\n",
    "\n",
    "**Limitations:**\n",
    "\n",
    "Less expressive power compared to modern deep networks.\n",
    "Prone to overfitting on small datasets.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l31nFoHwYYE7"
   },
   "source": [
    "## Feature Selection\n",
    "\n",
    "**Image Preprocessing Rescaling:** All pixel values were normalized to the [0, 1] range using rescale=1./255 to aid model convergence and numerical stability.\n",
    "Standardized Input Shape: All images were resized to 224×224 pixels to match the input requirements of models like ResNet50 and DenseNet121.\n",
    "\n",
    "**Data Augmentation:** To improve generalization and simulate variability in real-world data, the following augmentations were applied using ImageDataGenerator:\n",
    "* Horizontal Flip: Introduces invariance to image mirroring.\n",
    "* Rotation (±15 degrees): Helps the model become robust to slight rotations.\n",
    "* Zooming (±10%): Simulates scale variation and partial views.\n",
    "\n",
    "These augmentations act as a form of implicit feature engineering, improving the diversity of the training set without increasing its size.\n",
    "\n",
    "**Custom Loss Function (Focal Loss):** Replacing standard binary cross-entropy with focal loss introduced a class-weighting mechanism to tackle potential class imbalance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hjtFt0v6YYE8"
   },
   "outputs": [],
   "source": [
    "# paths to the dataset\n",
    "excel_path = \"C:/Users/user/Desktop/Tensor-FLow Project/Filik.xlsx\"\n",
    "image_src_dir = \"C:/Users/user/Desktop/Tensor-FLow Project/images\"  # папка где все .png\n",
    "target_base_dir = \"C:/Users/user/Desktop/Tensor-FLow Project/images_by_class\"  # новая структура\n",
    "\n",
    "# read Excel\n",
    "df = pd.read_excel(excel_path)\n",
    "df.columns = ['filename', 'label_str', 'partition']\n",
    "\n",
    "# organize dataset\n",
    "for _, row in df.iterrows():\n",
    "    label = row['label_str']   # HP or SSA\n",
    "    part = row['partition']    # train or test\n",
    "    fname = row['filename']\n",
    "\n",
    "    src_path = os.path.join(image_src_dir, fname)\n",
    "    dst_dir = os.path.join(target_base_dir, part, label)\n",
    "    dst_path = os.path.join(dst_dir, fname)\n",
    "\n",
    "    os.makedirs(dst_dir, exist_ok=True)\n",
    "\n",
    "    if os.path.exists(src_path):\n",
    "        shutil.copy(src_path, dst_path)\n",
    "    else:\n",
    "        print(f\"⚠️ File not found: {src_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y57DUAneYYE9"
   },
   "outputs": [],
   "source": [
    "# path to test folder\n",
    "test_dir = \"C:/Users/user/Desktop/Tensor-FLow Project/images_by_class/test\"\n",
    "\n",
    "data = []\n",
    "for label in ['HP', 'SSA']:\n",
    "    class_dir = os.path.join(test_dir, label)\n",
    "    for fname in os.listdir(class_dir):\n",
    "        data.append({\n",
    "            'filename': os.path.join(class_dir, fname),\n",
    "            'class': label\n",
    "        })\n",
    "\n",
    "df_test = pd.DataFrame(data)\n",
    "\n",
    "# Divide into validation and final test\n",
    "df_val, df_final_test = train_test_split(\n",
    "    df_test, test_size=0.2, stratify=df_test['class'], random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T4ugHyYHYYE-"
   },
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    horizontal_flip=True,\n",
    "    rotation_range=15,\n",
    "    zoom_range=0.1\n",
    ")\n",
    "\n",
    "train_gen = datagen.flow_from_directory(\n",
    "    \"C:/Users/user/Desktop/Tensor-FLow Project/images_by_class/train\",\n",
    "    target_size=(224, 224),\n",
    "    class_mode='binary',\n",
    "    batch_size=16,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_gen = datagen.flow_from_dataframe(\n",
    "    df_val,\n",
    "    x_col='filename',\n",
    "    y_col='class',\n",
    "    target_size=(224, 224),\n",
    "    class_mode='binary',\n",
    "    batch_size=16,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "test_gen = datagen.flow_from_dataframe(\n",
    "    df_final_test,\n",
    "    x_col='filename',\n",
    "    y_col='class',\n",
    "    target_size=(224, 224),\n",
    "    class_mode='binary',\n",
    "    batch_size=16,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S8aR_d-qYYE_"
   },
   "source": [
    "## Implementation\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eXw4pJpGZd3E"
   },
   "source": [
    "#### Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zULqa7AGZbwu"
   },
   "outputs": [],
   "source": [
    "!pip install keras-tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qV3-OyEeZbzH"
   },
   "outputs": [],
   "source": [
    "from keras_tuner import RandomSearch\n",
    "import keras_tuner as kt\n",
    "\n",
    "def focal_loss(gamma=2.0, alpha=0.75):\n",
    "    def loss(y_true, y_pred):\n",
    "        y_pred = K.clip(y_pred, K.epsilon(), 1. - K.epsilon())\n",
    "        alpha_t = tf.where(tf.equal(y_true, 1), alpha, 1 - alpha)\n",
    "        pt = tf.where(tf.equal(y_true, 1), y_pred, 1 - y_pred)\n",
    "        return -alpha_t * K.pow(1. - pt, gamma) * K.log(pt)\n",
    "    return loss\n",
    "\n",
    "\n",
    "def build_model(hp):\n",
    "    model = models.Sequential([\n",
    "        layers.Input(shape=(224, 224, 3)),\n",
    "\n",
    "        layers.Conv2D(hp.Int('conv1_filters', 32, 128, step=32), (3, 3), padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.ReLU(),\n",
    "        layers.MaxPooling2D(),\n",
    "        layers.Dropout(hp.Float('dropout1', 0.2, 0.5, step=0.1)),\n",
    "\n",
    "        layers.Conv2D(hp.Int('conv2_filters', 64, 256, step=64), (3, 3), padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.ReLU(),\n",
    "        layers.MaxPooling2D(),\n",
    "        layers.Dropout(hp.Float('dropout2', 0.2, 0.5, step=0.1)),\n",
    "\n",
    "        layers.Conv2D(hp.Int('conv3_filters', 128, 512, step=128), (3, 3), padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.ReLU(),\n",
    "        layers.MaxPooling2D(),\n",
    "        layers.Dropout(hp.Float('dropout3', 0.2, 0.5, step=0.1)),\n",
    "\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(hp.Int('dense_units', 128, 512, step=64)),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.ReLU(),\n",
    "        layers.Dropout(hp.Float('dropout4', 0.2, 0.5, step=0.1)),\n",
    "\n",
    "        layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optimizers.Adam(learning_rate=hp.Choice('lr', [1e-5])),\n",
    "        loss=focal_loss(gamma=hp.Choice('gamma', [1.5, 2.0]), alpha=hp.Choice('alpha', [0.5, 0.75])),\n",
    "        metrics=[\n",
    "            'accuracy',\n",
    "            metrics.AUC(name='auc'),\n",
    "            metrics.Recall(name='tpr'),\n",
    "            metrics.FalsePositives(name='fp'),\n",
    "            metrics.TruePositives(name='tp'),\n",
    "        ]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_auc',\n",
    "    max_trials=8,\n",
    "    executions_per_trial=1,\n",
    "    directory='cnn_tuning',\n",
    "    project_name='base_model_randomsearch'\n",
    ")\n",
    "\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=3,\n",
    "    min_delta=0.01,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "tuner.search(train_gen, validation_data=val_gen, epochs=15, callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cyGHneABZb1j"
   },
   "outputs": [],
   "source": [
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "best_hp = tuner.get_best_hyperparameters(1)[0]\n",
    "print(\"Best hyperparameters:\")\n",
    "print(best_hp.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3pWs-QQ3Zb3z"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Get all trials\n",
    "trials = tuner.oracle.trials.values()\n",
    "\n",
    "# Collect hyperparameters and metrics\n",
    "trial_data = []\n",
    "\n",
    "for trial in trials:\n",
    "    data = trial.hyperparameters.values.copy()  # Hyperparameters\n",
    "    data['trial_id'] = trial.trial_id\n",
    "\n",
    "    # Get metrics\n",
    "    for metric_name, metric_history in trial.metrics.metrics.items():\n",
    "        # Get the list of all metric's observations\n",
    "        observations = metric_history.get_history()\n",
    "        if observations:\n",
    "            # Take last metric value\n",
    "            last_value = observations[-1].value\n",
    "            data[metric_name] = last_value\n",
    "        else:\n",
    "            data[metric_name] = None  # if we don't have any observation\n",
    "\n",
    "    trial_data.append(data)\n",
    "\n",
    "# Convert to DataFrame\n",
    "df_trials = pd.DataFrame(trial_data)\n",
    "\n",
    "# Save\n",
    "df_trials.to_excel('C:/Users/user/Downloads/cnn_randomsearch_results1.xlsx', index=False)\n",
    "\n",
    "\n",
    "df_trials.head(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5r4PsGHJZpSa"
   },
   "source": [
    "#### Best trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jNYs0lQbYYFA"
   },
   "outputs": [],
   "source": [
    "model = models.Sequential([\n",
    "    layers.Input(shape=(224, 224, 3)),\n",
    "\n",
    "    layers.Conv2D(128, (3, 3), padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.ReLU(),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Dropout(0.2),\n",
    "\n",
    "    layers.Conv2D(64, (3, 3), padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.ReLU(),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Dropout(0.4),\n",
    "\n",
    "    layers.Conv2D(512, (3, 3), padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.ReLU(),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Dropout(0.3),\n",
    "\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(448),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.ReLU(),\n",
    "    layers.Dropout(0.3),\n",
    "\n",
    "    layers.Dense(1, activation='sigmoid')  # Выход\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HgG6ab4lYYFB"
   },
   "outputs": [],
   "source": [
    "def focal_loss(gamma=2.0, alpha=0.75):\n",
    "    def loss(y_true, y_pred):\n",
    "        y_pred = K.clip(y_pred, K.epsilon(), 1. - K.epsilon())\n",
    "        alpha_t = tf.where(tf.equal(y_true, 1), alpha, 1 - alpha)\n",
    "        pt = tf.where(tf.equal(y_true, 1), y_pred, 1 - y_pred)\n",
    "        return -alpha_t * K.pow(1. - pt, gamma) * K.log(pt)\n",
    "    return loss\n",
    "\n",
    "\n",
    "optimizer = optimizers.Adam(learning_rate=1e-4)\n",
    "\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss=focal_loss(gamma=1.5, alpha=0.5),\n",
    "              metrics=[\n",
    "        'accuracy',\n",
    "        metrics.AUC(name='auc'),\n",
    "        metrics.Recall(name='tpr'),     # TPR = Recall\n",
    "        metrics.FalsePositives(name='fp'),\n",
    "        metrics.TruePositives(name='tp'),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ISOfACGnYYFC"
   },
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=3,\n",
    "    min_delta=0.03,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "checkpoint = ModelCheckpoint(\n",
    "    'AfterSearchCNNbest_model.keras',\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    save_weights_only=False,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    train_gen,\n",
    "    validation_data=val_gen,\n",
    "    epochs=15,\n",
    "    callbacks=[checkpoint]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i6yRyqr6YYFC"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "BestCNNmodel = load_model('AfterSearchCNNbest_model.keras', custom_objects={'loss': focal_loss(gamma=1.5, alpha=0.75)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z3opgYc6YYFD"
   },
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'], label='train loss')\n",
    "plt.plot(history.history['val_loss'], label='val loss')\n",
    "plt.legend()\n",
    "plt.title(\"Loss over epochs\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.savefig('C:/Users/user/Desktop/Tensor-FLow Project/Plots/CNN/Best_loss_plot.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CT8Da-0cYYFE"
   },
   "source": [
    "## Evaluation\n",
    "\n",
    "We use loss, accuracy and AUC as our primary evaluation metrics. Accuracy provides a general performance measure, AUC gives insight into the model’s discriminatory power. Additionally, confusion matrices are used for detailed error analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9uiJQ0d8YYFD"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "\n",
    "# Plots\n",
    "plt.plot(history.history['loss'], label='Train loss',\n",
    "         color='#f64ad6', linewidth=2.5, marker='o')\n",
    "plt.plot(history.history['val_loss'], label='Validation loss',\n",
    "         color='#A0D400', linewidth=2.5, marker='s')\n",
    "\n",
    "# Design\n",
    "plt.title(\"Model loss\", fontsize=18, weight='bold')\n",
    "plt.xlabel(\"Epoch\", fontsize=14, weight='bold')\n",
    "plt.ylabel(\"Loss\", fontsize=14, weight='bold')\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.legend(fontsize=14)\n",
    "plt.grid(False)\n",
    "plt.tight_layout()\n",
    "plt.savefig('C:/Users/user/Desktop/Tensor-FLow Project/Plots/CNN/Forpres_Best_loss_plot.png', dpi=300, transparent=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oVIFrQQDYYFE"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "\n",
    "# Plots\n",
    "plt.plot(history.history['loss'], label='Train loss',\n",
    "         color='#f64ad6', linewidth=2.5, marker='o')\n",
    "plt.plot(history.history['val_loss'], label='Validation loss',\n",
    "         color='#A0D400', linewidth=2.5, marker='s')\n",
    "\n",
    "# Design\n",
    "plt.title(\"Model loss\", fontsize=18, weight='bold')\n",
    "plt.xlabel(\"Epoch\", fontsize=14, weight='bold')\n",
    "plt.ylabel(\"Loss\", fontsize=14, weight='bold')\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.legend(fontsize=14)\n",
    "plt.grid(False)\n",
    "plt.tight_layout()\n",
    "plt.savefig('C:/Users/user/Desktop/Tensor-FLow Project/Plots/CNN/Forpres_Best_loss_plot.png', dpi=300, transparent=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cFMGPhNGYYFF"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "\n",
    "# Plots\n",
    "plt.plot(history.history['auc'], label='Train AUC',\n",
    "         color='#f64ad6', linewidth=2.5, marker='o')\n",
    "plt.plot(history.history['val_auc'], label='validation AUC',\n",
    "         color='#A0D400', linewidth=2.5, marker='s')\n",
    "\n",
    "# Design\n",
    "plt.title(\"Model AUC\", fontsize=18, weight='bold')\n",
    "plt.xlabel(\"Epoch\", fontsize=14, weight='bold')\n",
    "plt.ylabel(\"AUC\", fontsize=14, weight='bold')\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.legend(fontsize=12)\n",
    "plt.grid(False)\n",
    "plt.tight_layout()\n",
    "plt.savefig('C:/Users/user/Desktop/Tensor-FLow Project/Plots/CNN/Forpres_Best_AUC_plot.png', dpi=300, transparent=True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
