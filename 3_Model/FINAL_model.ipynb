{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bdh1IIb5mCG7"
      },
      "source": [
        "# Model Definition and Evaluation\n",
        "## Table of Contents\n",
        "1. [Model Selection](#model-selection)\n",
        "2. [Feature Engineering](#feature-engineering)\n",
        "3. [Hyperparameter Tuning](#hyperparameter-tuning)\n",
        "4. [Implementation](#implementation)\n",
        "5. [Evaluation Metrics](#evaluation-metrics)\n",
        "6. [Comparative Analysis](#comparative-analysis)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Va5lrrATmCHA"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.applications import DenseNet121\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D4cEiE5vmCHC"
      },
      "source": [
        "## Model Selection\n",
        "\n",
        "We choose DenseNet121 for classifying histological images of hyperplastic polyps (HP) and sessile serrated adenomas (SSA) because its dense connectivity promotes efficient feature reuse and better gradient flow, enabling the model to capture subtle morphological differences critical in histopathology. Its parameter efficiency helps reduce overfitting, especially when working with limited medical datasets, and it has a strong track record in various medical imaging tasks—including cancer detection—where fine-grained tissue structures must be distinguished. These advantages make DenseNet121 well-suited for the nuanced and detail-sensitive task of differentiating HP from SSA in colon histology.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mBnEdJNLmCHC"
      },
      "source": [
    "## Feature Engineering\n",
    "\n",
    "- **Image Preprocessing – Rescaling**: All pixel values were normalized to the [0, 1] range using `rescale=1./255` to aid model convergence and numerical stability.\n",
    "- **Standardized Input Shape**: All images were resized to 224×224 pixels to match the input requirements of models like ResNet50 and DenseNet121.\n",
    "- **Data Augmentation**: To improve generalization and simulate variability in real‑world data, the following augmentations were applied using `ImageDataGenerator`:\n",
    "  - Horizontal flip: introduces invariance to mirroring\n",
    "  - Rotation (±15°): robustness to slight rotations\n",
    "  - Zoom (±10%): simulates scale variation and partial views\n",
    "- **Custom Loss Function (Focal Loss)**: Replaced standard binary cross‑entropy to handle potential class imbalance."
  ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oLh3RzZXmCHD"
      },
      "outputs": [],
      "source": [
        "Same as in Baseline_model.ipynb\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MDqPqBjgmCHD"
      },
      "source": [
        "## Hyperparameter Tuning\n",
        "\n",
        "We used Random Search, to find best parameters (how many layers to unfreeze, numbers of newrons, dropout rate, etc.) for final implementation.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JDzBFpsOmCHE"
      },
      "source": [
        "## Random search"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Before fine-tuning"
      ],
      "metadata": {
        "id": "NmCrliDVbi5q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "srSl3QCfmCHF"
      },
      "outputs": [],
      "source": [
        "from keras_tuner import RandomSearch\n",
        "import keras_tuner as kt\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "def build_feature_extraction_model(hp):\n",
        "    base_model = DenseNet121(weights='imagenet', include_top=False, input_shape=(224, 224, 3), name='densenet121_base')\n",
        "    base_model.trainable = False\n",
        "\n",
        "    x = base_model.output\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Dense(hp.Int('dense_units', 64, 256, step=64))(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = tf.keras.layers.ReLU()(x)\n",
        "    x = Dropout(hp.Float('dropout', 0.2, 0.5, step=0.1))(x)\n",
        "    output = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "    model = Model(inputs=base_model.input, outputs=output)\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=Adam(learning_rate=hp.Choice('lr', [1e-5])),\n",
        "        loss=focal_loss(gamma=hp.Choice('gamma', [1.5, 2.0]), alpha=hp.Choice('alpha', [0.5, 0.75])),\n",
        "        metrics=['accuracy', tf.keras.metrics.AUC(name='auc')]\n",
        "    )\n",
        "    return model\n",
        "\n",
        "early_stop = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=3,\n",
        "    min_delta=0.01,\n",
        "    restore_best_weights=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "tuner = RandomSearch(\n",
        "    build_feature_extraction_model,\n",
        "    objective='val_auc',\n",
        "    max_trials=10,\n",
        "    directory='densenet_tuning',\n",
        "    project_name='feature_extraction'\n",
        ")\n",
        "\n",
        "tuner.search(train_gen, validation_data=val_gen, epochs=11, callbacks=[early_stop])\n",
        "\n",
        "# best_model = tuner.get_best_models(1)[0]\n",
        "# best_model.save('best_densenet_model.keras')\n",
        "\n",
        "best_hp = tuner.get_best_hyperparameters(1)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ExuG_2GNmCHG"
      },
      "outputs": [],
      "source": [
        "# Collecting data from all trials\n",
        "trials_data = []\n",
        "\n",
        "for trial in tuner.oracle.trials.values():\n",
        "    hp_values = trial.hyperparameters.values\n",
        "    metrics = trial.metrics.get_best_value('val_auc')  # целевая метрика\n",
        "\n",
        "    row = {\n",
        "        'Trial_ID': trial.trial_id,\n",
        "        'val_auc': metrics,\n",
        "        'val_loss': trial.metrics.get_last_value('val_loss'),\n",
        "        'accuracy': trial.metrics.get_last_value('accuracy'),\n",
        "        'val_accuracy': trial.metrics.get_last_value('val_accuracy'),\n",
        "        'loss': trial.metrics.get_last_value('loss'),\n",
        "        **hp_values\n",
        "    }\n",
        "    trials_data.append(row)\n",
        "\n",
        "\n",
        "df = pd.DataFrame(trials_data)\n",
        "\n",
        "\n",
        "df.to_excel(\"C:/Users/user/Desktop/Tensor-FLow Project/DenseNetRandomSearch2.xlsx\", index=False)\n",
        "\n",
        "# Show the table (Jupyter/Colab)\n",
        "from IPython.display import display\n",
        "display(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZuith1tmCHG"
      },
      "source": [
        "### Fine tuning (working with frozen layers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g9ZWdOXTmCHH"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "base_model_full = load_model(\n",
        "    'best_densenet_model.keras',\n",
        "    custom_objects={'loss': focal_loss(gamma=1.0, alpha=0.75)}\n",
        ")\n",
        "\n",
        "from tensorflow.keras.models import clone_model\n",
        "\n",
        "def build_fine_tune_model(hp):\n",
        "    from tensorflow.keras.models import clone_model\n",
        "\n",
        "    # Clone model and set weights\n",
        "    model = clone_model(base_model_full)\n",
        "    model.set_weights(base_model_full.get_weights())\n",
        "\n",
        "    # How many layers to unfreeze\n",
        "    unfreeze_layers = hp.Int('unfreeze_layers', min_value=20, max_value=100, step=20)\n",
        "\n",
        "    # Unfreeze only the convolutional and normalization layers from the base model\n",
        "    base_layers = [layer for layer in model.layers if any(substr in layer.name for substr in ['conv', 'bn', 'pool'])]\n",
        "\n",
        "    # Unfreeze last N layers\n",
        "    for layer in base_layers[-unfreeze_layers:]:\n",
        "        layer.trainable = True\n",
        "    for layer in base_layers[:-unfreeze_layers]:\n",
        "        layer.trainable = False\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=Adam(learning_rate=hp.Choice('lr', [1e-5, 3e-5])),\n",
        "        loss=focal_loss(gamma=1.0, alpha=0.75),\n",
        "        metrics=['accuracy', tf.keras.metrics.AUC(name='auc')]\n",
        "    )\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pPscM8J5mCHH"
      },
      "outputs": [],
      "source": [
        "fine_tuner_new = RandomSearch(\n",
        "    build_fine_tune_model,\n",
        "    objective='val_auc',\n",
        "    max_trials=10,\n",
        "    directory='densenet_tuning_new_',\n",
        "    project_name='fine_tuning_new_'\n",
        ")\n",
        "\n",
        "fine_tuner_new.search(train_gen, validation_data=val_gen, epochs=12)\n",
        "\n",
        "# , callbacks=[early_stop]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YReecn_rmCHI"
      },
      "outputs": [],
      "source": [
        "best_finetuned_model = fine_tuner.get_best_models(1)[0]\n",
        "best_finetuned_model.save('best_densenet_new_finetuned_model.keras')\n",
        "\n",
        "best_fine_hp = fine_tuner.get_best_hyperparameters(1)[0]\n",
        "print(best_fine_hp.values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iROBNwmZmCHI"
      },
      "outputs": [],
      "source": [
        "# Collect data from all trials\n",
        "trials_data = []\n",
        "\n",
        "for trial in fine_tuner_new.oracle.trials.values():\n",
        "    hp_values = trial.hyperparameters.values\n",
        "    metrics = trial.metrics.get_best_value('val_auc')  # целевая метрика\n",
        "\n",
        "    row = {\n",
        "        'Trial_ID': trial.trial_id,\n",
        "        'val_auc': metrics,\n",
        "        'val_loss': trial.metrics.get_last_value('val_loss'),\n",
        "        'accuracy': trial.metrics.get_last_value('accuracy'),\n",
        "        'val_accuracy': trial.metrics.get_last_value('val_accuracy'),\n",
        "        'loss': trial.metrics.get_last_value('loss'),\n",
        "        **hp_values\n",
        "    }\n",
        "    trials_data.append(row)\n",
        "\n",
        "df = pd.DataFrame(trials_data)\n",
        "\n",
        "df.to_excel(\"C:/Users/user/Desktop/Tensor-FLow Project/DenseNetRandomSearch2_new_.xlsx\", index=False)\n",
        "\n",
        "from IPython.display import display\n",
        "display(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qpNrl93MmCHJ"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Load model without the custom_objects\n",
        "model = load_model('best_densenet_new_finetuned_model.keras', compile=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ttcbtMBbmCHJ"
      },
      "outputs": [],
      "source": [
        "# Compile once again\n",
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=1e-5),\n",
        "    loss=focal_loss(gamma=1.0, alpha=0.75),\n",
        "    metrics=['accuracy', tf.keras.metrics.AUC(name='auc')]\n",
        ")\n",
        "\n",
        "# evaluate the model\n",
        "loss, accuracy, auc = model.evaluate(val_gen)\n",
        "print(f\"Loss: {loss:.4f} | Accuracy: {accuracy:.4f} | AUC: {auc:.4f}\")\n",
        "\n",
        "# some manual control which labels does the model predict - creating predictions\n",
        "#with appropriate probabilities for each observation\n",
        "\n",
        "pred_probs = model.predict(test_gen)\n",
        "\n",
        "pred_labels = (pred_probs > 0.5).astype(int).flatten()\n",
        "\n",
        "true_labels = test_gen.classes\n",
        "class_names = list(test_gen.class_indices.keys())\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "results = pd.DataFrame({\n",
        "    'Filename': test_gen.filenames,\n",
        "    'True': [class_names[i] for i in true_labels],\n",
        "    'Predicted': [class_names[i] for i in pred_labels]\n",
        "})\n",
        "\n",
        "results.head(40)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kINW5vyumCHJ"
      },
      "source": [
        "## Implementation\n",
        "\n",
        "Final model implementation:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Before fine-tuning"
      ],
      "metadata": {
        "id": "igfFXiOadEu-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3npBz3kMmCHK"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "import pickle\n",
        "\n",
        "\n",
        "# Download the DenseNet121 model\n",
        "base_model = DenseNet121(\n",
        "    weights='imagenet',\n",
        "    include_top=False,\n",
        "    input_shape=(224, 224, 3)\n",
        ")\n",
        "\n",
        "# Freeze the base model\n",
        "base_model.trainable = False\n",
        "\n",
        "\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(128)(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = tf.keras.layers.ReLU()(x)\n",
        "x = Dropout(0.2)(x)\n",
        "output = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=output)\n",
        "\n",
        "\n",
        "def focal_loss(gamma=2.0, alpha=0.75):\n",
        "    def loss(y_true, y_pred):\n",
        "        y_pred = tf.clip_by_value(y_pred, tf.keras.backend.epsilon(), 1. - tf.keras.backend.epsilon())\n",
        "        alpha_t = tf.where(tf.equal(y_true, 1), alpha, 1 - alpha)\n",
        "        pt = tf.where(tf.equal(y_true, 1), y_pred, 1 - y_pred)\n",
        "        return -alpha_t * tf.pow(1. - pt, gamma) * tf.math.log(pt)\n",
        "    return loss\n",
        "\n",
        "\n",
        "\n",
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=0.0001),\n",
        "    loss=focal_loss(gamma=1.0, alpha=0.75), #'binary_crossentropy'\n",
        "    metrics=['accuracy', tf.keras.metrics.AUC(name='auc')]\n",
        ")\n",
        "\n",
        "\n",
        "callbacks = [\n",
        "    ModelCheckpoint('FINAL_densenet_model_with_history.keras', save_best_only=True),\n",
        "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2)\n",
        "]\n",
        "\n",
        "\n",
        "history_Densebefore = model.fit(\n",
        "    train_gen,\n",
        "    validation_data=val_gen,\n",
        "    epochs=15,\n",
        "    callbacks=callbacks\n",
        ")\n",
        "\n",
        "with open('FINAL_densenet_history.pkl', 'wb') as f:\n",
        "    pickle.dump(history_Densebefore.history, f)\n",
        "\n",
        "\n",
        "model = load_model(\n",
        "    'FINAL_densenet_model_with_history.keras',\n",
        "    custom_objects={'loss': focal_loss(gamma=1.0, alpha=0.75)}\n",
        ")\n",
        "\n",
        "with open('FINAL_densenet_history.pkl', 'rb') as f:\n",
        "    history_Densebefore = pickle.load(f)\n",
        "\n",
        "\n",
        "pred_probs = model.predict(test_gen)\n",
        "\n",
        "\n",
        "pred_labels = (pred_probs > 0.5).astype(int).flatten()\n",
        "\n",
        "true_labels = test_gen.classes\n",
        "class_names = list(test_gen.class_indices.keys())\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "results = pd.DataFrame({\n",
        "    'Filename': test_gen.filenames,\n",
        "    'True': [class_names[i] for i in true_labels],\n",
        "    'Predicted': [class_names[i] for i in pred_labels]\n",
        "})"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Some plots"
      ],
      "metadata": {
        "id": "tSzJDC-ccrmY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.colors import LinearSegmentedColormap\n",
        "\n",
        "# Creating a custom colormap\n",
        "custom_cmap = LinearSegmentedColormap.from_list(\"custom_gradient\", [\"#ff90ea\", \"#dbff6c\"])\n",
        "\n",
        "# Confusion matrix\n",
        "cm = confusion_matrix(true_labels, pred_labels)\n",
        "\n",
        "plt.figure(figsize=(6, 5))\n",
        "sns.heatmap(cm,\n",
        "            annot=True,\n",
        "            fmt='d',\n",
        "            cmap=custom_cmap,  # градиент\n",
        "            xticklabels=class_names,\n",
        "            yticklabels=class_names,\n",
        "            cbar=True,\n",
        "            linewidths=1,\n",
        "            linecolor='white',\n",
        "            annot_kws={\"size\": 14, \"weight\": \"bold\", \"color\": \"black\"})\n",
        "\n",
        "# Formatting\n",
        "plt.title(\"Confusion Matrix\", fontsize=18, weight='bold')\n",
        "plt.xlabel(\"Predicted\", fontsize=14, weight='bold')\n",
        "plt.ylabel(\"True\", fontsize=14, weight='bold')\n",
        "plt.xticks(fontsize=12)\n",
        "plt.yticks(fontsize=12)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('C:/Users/user/Desktop/Tensor-FLow Project/Plots/DenseNet/Denseforpres_confision_matrix_plot.png',\n",
        "            dpi=300, transparent=True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "yMNTxiuec061"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8, 5))\n",
        "\n",
        "\n",
        "plt.plot(history_Densebefore['loss'], label='Train loss',\n",
        "         color='#f64ad6', linewidth=2.5, marker='o')\n",
        "plt.plot(history_Densebefore['val_loss'], label='Validation loss',\n",
        "         color='#A0D400', linewidth=2.5, marker='s')\n",
        "\n",
        "# Оформление\n",
        "plt.title(\"Model loss\", fontsize=18, weight='bold')\n",
        "plt.xlabel(\"Epoch\", fontsize=14, weight='bold')\n",
        "plt.ylabel(\"Loss\", fontsize=14, weight='bold')\n",
        "plt.xticks(fontsize=14)\n",
        "plt.yticks(fontsize=14)\n",
        "plt.legend(fontsize=14)\n",
        "plt.grid(False)\n",
        "plt.tight_layout()\n",
        "plt.savefig('C:/Users/user/Desktop/Tensor-FLow Project/Plots/DenseNet/Denseforpres_loss_plot.png', dpi=300, transparent=True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "5uKlWMgpc084"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8, 5))\n",
        "\n",
        "\n",
        "plt.plot(history_Densebefore['accuracy'], label='Train Accuracy',\n",
        "         color='#f64ad6', linewidth=2.5, marker='o')\n",
        "plt.plot(history_Densebefore['val_accuracy'], label='Validation Accuracy',\n",
        "         color='#A0D400', linewidth=2.5, marker='s')\n",
        "\n",
        "plt.title(\"Model Accuracy\", fontsize=18, weight='bold')\n",
        "plt.xlabel(\"Epoch\", fontsize=14, weight='bold')\n",
        "plt.ylabel(\"Accuracy\", fontsize=14, weight='bold')\n",
        "plt.xticks(fontsize=14)\n",
        "plt.yticks(fontsize=14)\n",
        "plt.legend(fontsize=14)\n",
        "plt.grid(False)\n",
        "plt.tight_layout()\n",
        "plt.savefig('C:/Users/user/Desktop/Tensor-FLow Project/Plots/DenseNet/Denseforpres_Accuracy_plot.png', dpi=300, transparent=True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "fIcV5M39c0-l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8, 5))\n",
        "\n",
        "\n",
        "plt.plot(history_Densebefore['auc'], label='Train AUC',\n",
        "         color='#f64ad6', linewidth=2.5, marker='o')\n",
        "plt.plot(history_Densebefore['val_auc'], label='validation AUC',\n",
        "         color='#A0D400', linewidth=2.5, marker='s')\n",
        "\n",
        "\n",
        "plt.title(\"Model AUC\", fontsize=18, weight='bold')\n",
        "plt.xlabel(\"Epoch\", fontsize=14, weight='bold')\n",
        "plt.ylabel(\"AUC\", fontsize=14, weight='bold')\n",
        "plt.xticks(fontsize=12)\n",
        "plt.yticks(fontsize=12)\n",
        "plt.legend(fontsize=12)\n",
        "plt.grid(False)\n",
        "plt.tight_layout()\n",
        "plt.savefig('C:/Users/user/Desktop/Tensor-FLow Project/Plots/DenseNet/Denseforpres_AUC_plot.png', dpi=300, transparent=True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "BMVQe2rkc1Ae"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### After fine-tuning"
      ],
      "metadata": {
        "id": "--Ykj_b-dJj8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_model.trainable = True\n",
        "\n",
        "# Freeze the first 100 layers\n",
        "for layer in base_model.layers[:-100]:\n",
        "    layer.trainable = False\n",
        "\n",
        "# early_stop = EarlyStopping(\n",
        "#     monitor='val_auc',\n",
        "#     patience=3,\n",
        "#     min_delta=0.01,\n",
        "#     restore_best_weights=True,\n",
        "#     verbose=1\n",
        "# )\n",
        "\n",
        "\n",
        "# Recompile the model with a learning rate\n",
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=3e-05),\n",
        "    loss=focal_loss(gamma=1.0, alpha=0.75), #'binary_crossentropy',\n",
        "    metrics=['accuracy', tf.keras.metrics.AUC(name='auc')]\n",
        ")\n",
        "\n",
        "# Continue training\n",
        "history_afterfine = model.fit(\n",
        "    train_gen,\n",
        "    validation_data=val_gen,\n",
        "    epochs=15,\n",
        "    callbacks=callbacks\n",
        ")\n",
        "\n",
        "with open('afterFINAL_densenet_history.pkl', 'wb') as k:\n",
        "    pickle.dump(history_afterfine.history, k)\n",
        "\n",
        "model.save('FINAL_finetuned_densenet_model.keras')"
      ],
      "metadata": {
        "id": "yCyGh8x2c1C_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = load_model(\n",
        "    'FINAL_finetuned_densenet_model.keras',\n",
        "    custom_objects={'loss': focal_loss(gamma=1.0, alpha=0.75)}\n",
        ")\n",
        "\n",
        "with open('afterFINAL_densenet_history.pkl', 'rb') as k:\n",
        "    history_afterfine = pickle.load(k)"
      ],
      "metadata": {
        "id": "-ylwUnjR53kR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "pred_probs = model.predict(test_gen)\n",
        "\n",
        "\n",
        "pred_labels = (pred_probs > 0.5).astype(int).flatten()\n",
        "\n",
        "true_labels = test_gen.classes\n",
        "class_names = list(test_gen.class_indices.keys())\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "results = pd.DataFrame({\n",
        "    'Filename': test_gen.filenames,\n",
        "    'True': [class_names[i] for i in true_labels],\n",
        "    'Predicted': [class_names[i] for i in pred_labels]\n",
        "})\n",
        "\n",
        "results.head(40)"
      ],
      "metadata": {
        "id": "vuwWgeif6oHs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Some plots"
      ],
      "metadata": {
        "id": "71LYQOu8dS1a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating custom colormap\n",
        "custom_cmap = LinearSegmentedColormap.from_list(\"custom_gradient\", [\"#ff90ea\", \"#dbff6c\"])\n",
        "\n",
        "# Confusion matrix\n",
        "cm = confusion_matrix(true_labels, pred_labels)\n",
        "\n",
        "plt.figure(figsize=(6, 5))\n",
        "sns.heatmap(cm,\n",
        "            annot=True,\n",
        "            fmt='d',\n",
        "            cmap=custom_cmap,  # gradient\n",
        "            xticklabels=class_names,\n",
        "            yticklabels=class_names,\n",
        "            cbar=True,\n",
        "            linewidths=1,\n",
        "            linecolor='white',\n",
        "            annot_kws={\"size\": 14, \"weight\": \"bold\", \"color\": \"black\"})\n",
        "\n",
        "# Formatting\n",
        "plt.title(\"Confusion Matrix\", fontsize=18, weight='bold')\n",
        "plt.xlabel(\"Predicted\", fontsize=14, weight='bold')\n",
        "plt.ylabel(\"True\", fontsize=14, weight='bold')\n",
        "plt.xticks(fontsize=12)\n",
        "plt.yticks(fontsize=12)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('C:/Users/user/Desktop/Tensor-FLow Project/Plots/DenseNet/Aftertune_Denseforpres_confision_matrix_plot.png',\n",
        "            dpi=300, transparent=True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "UGTZl9TudZdQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8, 5))\n",
        "\n",
        "# Graphs with custom colors\n",
        "plt.plot(history_afterfine['loss'], label='Train loss',\n",
        "         color='#f64ad6', linewidth=2.5, marker='o')\n",
        "plt.plot(history_afterfine['val_loss'], label='Validation loss',\n",
        "         color='#A0D400', linewidth=2.5, marker='s')\n",
        "\n",
        "# Formatting\n",
        "plt.title(\"Model loss\", fontsize=18, weight='bold')\n",
        "plt.xlabel(\"Epoch\", fontsize=14, weight='bold')\n",
        "plt.ylabel(\"Loss\", fontsize=14, weight='bold')\n",
        "plt.xticks(fontsize=14)\n",
        "plt.yticks(fontsize=14)\n",
        "plt.legend(fontsize=14)\n",
        "plt.grid(False)\n",
        "plt.tight_layout()\n",
        "plt.savefig('C:/Users/user/Desktop/Tensor-FLow Project/Plots/DenseNet/Aftertune_Denseforpres_loss_plot.png', dpi=300, transparent=True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "andxOjegdZfy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8, 5))\n",
        "\n",
        "\n",
        "plt.plot(history_afterfine['accuracy'], label='Train Accuracy',\n",
        "         color='#f64ad6', linewidth=2.5, marker='o')\n",
        "plt.plot(history_afterfine['val_accuracy'], label='Validation Accuracy',\n",
        "         color='#A0D400', linewidth=2.5, marker='s')\n",
        "\n",
        "\n",
        "plt.title(\"Model Accuracy\", fontsize=18, weight='bold')\n",
        "plt.xlabel(\"Epoch\", fontsize=14, weight='bold')\n",
        "plt.ylabel(\"Accuracy\", fontsize=14, weight='bold')\n",
        "plt.xticks(fontsize=14)\n",
        "plt.yticks(fontsize=14)\n",
        "plt.legend(fontsize=14)\n",
        "plt.grid(False)\n",
        "plt.tight_layout()\n",
        "plt.savefig('C:/Users/user/Desktop/Tensor-FLow Project/Plots/DenseNet/Aftertune_Denseforpres_Accuracy_plot.png', dpi=300, transparent=True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "B40DlauVdZiQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8, 5))\n",
        "\n",
        "\n",
        "plt.plot(history_afterfine['auc'], label='Train AUC',\n",
        "         color='#f64ad6', linewidth=2.5, marker='o')\n",
        "plt.plot(history_afterfine['val_auc'], label='validation AUC',\n",
        "         color='#A0D400', linewidth=2.5, marker='s')\n",
        "\n",
        "\n",
        "plt.title(\"Model AUC\", fontsize=18, weight='bold')\n",
        "plt.xlabel(\"Epoch\", fontsize=14, weight='bold')\n",
        "plt.ylabel(\"AUC\", fontsize=14, weight='bold')\n",
        "plt.xticks(fontsize=12)\n",
        "plt.yticks(fontsize=12)\n",
        "plt.legend(fontsize=12)\n",
        "plt.grid(False)\n",
        "plt.tight_layout()\n",
        "plt.savefig('C:/Users/user/Desktop/Tensor-FLow Project/Plots/DenseNet/Aftertune_Denseforpres_AUC_plot.png', dpi=300, transparent=True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rDtXDBBpdalq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ch3MBQrzmCHK"
      },
      "source": [
        "## Evaluation Metrics\n",
        "\n",
        "We use loss, accuracy and AUC as our primary evaluation metrics. Accuracy provides a general performance measure, AUC gives insight into the model’s discriminatory power. Additionally, confusion matrices are used for detailed error analysis.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check images with heatlabels"
      ],
      "metadata": {
        "id": "6VHl0wzpdxF_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import load_model\n",
        "from tf_keras_vis.gradcam import Gradcam\n",
        "from tf_keras_vis.utils.model_modifiers import ReplaceToLinear\n",
        "from tf_keras_vis.utils.scores import CategoricalScore\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.densenet import preprocess_input"
      ],
      "metadata": {
        "id": "dBCJIU2WdnS5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tf-keras-vis"
      ],
      "metadata": {
        "id": "hb2l8WHIdnVE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_images = 10\n",
        "batch_x, batch_y = test_gen[0]\n",
        "batch_pred_probs = model.predict(batch_x)\n",
        "batch_pred_labels = (batch_pred_probs > 0.5).astype(int).flatten()\n",
        "\n",
        "class_names = list(test_gen.class_indices.keys())\n",
        "\n",
        "fig, axes = plt.subplots(n_images, 3, figsize=(12, n_images * 3))\n",
        "\n",
        "for i in range(n_images):\n",
        "    img = batch_x[i]\n",
        "    img_input = np.expand_dims(img.copy(), axis=0)\n",
        "    img_input = preprocess_input(img_input)\n",
        "\n",
        "    cam = gradcam(binary_score(0), img_input, penultimate_layer='conv5_block16_2_conv')[0]\n",
        "    heatmap = np.maximum(cam, 0)\n",
        "    heatmap = heatmap / np.max(heatmap)\n",
        "\n",
        "    true_label = class_names[int(batch_y[i])]\n",
        "    pred_label = class_names[int(batch_pred_labels[i])]\n",
        "    prob = batch_pred_probs[i][0]\n",
        "\n",
        "    # Signatures\n",
        "    title = f'True: {true_label} | Pred: {pred_label} ({prob:.2f})'\n",
        "\n",
        "    axes[i, 0].imshow(img)\n",
        "    axes[i, 0].set_title('Оригинал\\n' + title)\n",
        "\n",
        "    axes[i, 1].imshow(heatmap, cmap='jet')\n",
        "    axes[i, 1].set_title('Тепловая карта')\n",
        "\n",
        "    axes[i, 2].imshow(img)\n",
        "    axes[i, 2].imshow(heatmap, cmap='jet', alpha=0.5)\n",
        "    axes[i, 2].set_title('Grad-CAM наложение')\n",
        "\n",
        "    for j in range(3):\n",
        "        axes[i, j].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "h9_XBdE2dnXh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from matplotlib import pyplot as plt\n",
        "from matplotlib import cm\n",
        "from PIL import Image\n",
        "\n",
        "# directory to save the plots\n",
        "save_dir = \"C:/Users/user/Desktop/Tensor-FLow Project/Plots/Maps\"\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "n_images = 10\n",
        "batch_x, batch_y = test_gen[0]\n",
        "batch_pred_probs = model.predict(batch_x)\n",
        "batch_pred_labels = (batch_pred_probs > 0.5).astype(int).flatten()\n",
        "\n",
        "class_names = list(test_gen.class_indices.keys())\n",
        "\n",
        "for i in range(n_images):\n",
        "    img = batch_x[i]\n",
        "    img_input = np.expand_dims(img.copy(), axis=0)\n",
        "    img_input = preprocess_input(img_input)\n",
        "\n",
        "    cam = gradcam(binary_score(0), img_input, penultimate_layer='conv5_block16_2_conv')[0]\n",
        "    heatmap = np.maximum(cam, 0)\n",
        "    heatmap = heatmap / (np.max(heatmap) + 1e-8)  # avoid division by zero\n",
        "\n",
        "    true_label = class_names[int(batch_y[i])]\n",
        "    pred_label = class_names[int(batch_pred_labels[i])]\n",
        "    prob = batch_pred_probs[i][0]\n",
        "    tag = f\"{i+1:02d}_T-{true_label}_P-{pred_label}_{prob:.2f}\"\n",
        "\n",
        "\n",
        "    # 1. Original\n",
        "    plt.imsave(os.path.join(save_dir, f\"{tag}_original.png\"), img)\n",
        "\n",
        "    # 2. Heatmap\n",
        "    plt.imsave(os.path.join(save_dir, f\"{tag}_heatmap.png\"), heatmap, cmap='jet')\n",
        "\n",
        "    # 3. Grad-CAM overlay\n",
        "    overlay = img.copy()\n",
        "    heatmap_colored = cm.jet(heatmap)[..., :3]\n",
        "    overlay = (0.6 * img + 0.4 * heatmap_colored)\n",
        "    overlay = np.clip(overlay, 0, 1)\n",
        "    plt.imsave(os.path.join(save_dir, f\"{tag}_overlay.png\"), overlay)\n",
        "\n",
        "print(f\"Saved {n_images * 3} images to: {save_dir}\")"
      ],
      "metadata": {
        "id": "HkaAsrIJdnZ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wKJsFKM3dncP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NRnZeyWqmCHL"
      },
      "source": [
        "## Comparative Analysis\n",
        "\n",
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To evaluate model performance, we compared the baseline CNN model with the proposed DenseNet121 model using three key metrics: **accuracy**, **loss**, and **AUC (Area Under the ROC Curve)**.\n",
        "\n",
        "| Metric     | Baseline CNN | DenseNet121 |\n",
        "|------------|--------------|-------------|\n",
        "| Accuracy   | 63.85%       | **84.92%**  |\n",
        "| Loss       | 0.3205       | **0.0671**  |\n",
        "| AUC        | 82.29        | **93.51**   |\n",
        "\n",
        "DenseNet121 significantly outperformed the baseline CNN model across all metrics. The accuracy improved by over **21%**, indicating better classification performance. The **reduction in loss** reflects more confident and consistent predictions. Additionally, the higher **AUC** (93.51 vs. 82.29) demonstrates superior capability of DenseNet121 in distinguishing between hyperplastic polyps and sessile serrated adenomas, making it a more reliable model for histopathological classification."
      ]
    },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Future Improvements\n",
        "\n",
        "- **Color normalization**: Convert images from RGB to YUV or YCbCr to separate luminance (structure) from chrominance (color), reducing the model's reliance on staining variations and improving generalization across datasets.\n",
        "\n",
        "- **Enhanced computational resources**: Utilize more powerful GPUs or cloud-based training environments to support larger models, deeper training, and more extensive hyperparameter tuning.\n",
        "\n",
        "- **Dataset expansion**: Incorporate additional histological datasets for both hyperplastic polyps (HP) and sessile serrated adenomas (SSA) to improve model robustness and reduce overfitting.\n",
        "\n",
        "- **Comprehensive model pipeline**: Gather richer metadata (e.g., clinical context, magnification level) to develop a more clinically applicable and fully deployable classification system.\n",
        "\n",
        "- **Extended training**: Train for more epochs with appropriate regularization and monitoring (e.g., early stopping) to enhance performance without overfitting."
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
